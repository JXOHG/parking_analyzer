{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv9 Training for CARPK Parking Dataset\n",
    "\n",
    "This notebook trains a YOLOv9 model on the prepared parking space dataset.\n",
    "\n",
    "## Notebook Structure\n",
    "1. System Setup and Requirements\n",
    "2. YOLOv9 Repository Configuration\n",
    "3. Pretrained Weights Download\n",
    "4. Training Configuration\n",
    "5. Model Training\n",
    "6. Results Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System Setup and Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "print(\"Checking system configuration...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory_gb:.2f} GB\")\n",
    "    \n",
    "    if gpu_memory_gb < 8:\n",
    "        print(f\"\\nNote: GPU has {gpu_memory_gb:.1f} GB memory\")\n",
    "        print(\"Recommended: batch_size 2-4, img_size 640 or lower\")\n",
    "else:\n",
    "    print(\"No GPU detected. Training will be slow on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YOLOv9 Repository Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def setup_yolov9_repository(yolov9_dir='./yolov9', force_reclone=False):\n",
    "    '''\n",
    "    Clone YOLOv9 repository and verify structure\n",
    "    '''\n",
    "    yolov9_path = Path(yolov9_dir)\n",
    "    \n",
    "    # If force_reclone or folder doesn't exist, clone fresh\n",
    "    if force_reclone and yolov9_path.exists():\n",
    "        print(\"Force re-clone requested. Attempting to remove existing directory...\")\n",
    "        \n",
    "        # Try to remove, with retries\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # On Windows, sometimes need to wait a moment\n",
    "                time.sleep(1)\n",
    "                shutil.rmtree(yolov9_path, ignore_errors=True)\n",
    "                time.sleep(1)\n",
    "                \n",
    "                if not yolov9_path.exists():\n",
    "                    print(\"Old directory removed successfully\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Retry {attempt + 1}/{max_retries}...\")\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    print(f\"\\nCannot automatically delete the folder.\")\n",
    "                    print(f\"Please manually delete: {yolov9_path.absolute()}\")\n",
    "                    print(\"Then run this cell again.\")\n",
    "                    raise\n",
    "    \n",
    "    # Check if we need to clone\n",
    "    needs_clone = False\n",
    "    \n",
    "    if not yolov9_path.exists():\n",
    "        needs_clone = True\n",
    "    else:\n",
    "        # Check if train.py exists\n",
    "        train_script = yolov9_path / 'train.py'\n",
    "        if not train_script.exists():\n",
    "            print(f\"YOLOv9 directory exists but train.py is missing\")\n",
    "            needs_clone = True\n",
    "        else:\n",
    "            print(f\"YOLOv9 directory verified at {yolov9_path}\")\n",
    "    \n",
    "    # Clone if needed\n",
    "    if needs_clone:\n",
    "        if yolov9_path.exists():\n",
    "            print(\"\\nThe yolov9 folder is incomplete. Please:\")\n",
    "            print(f\"  1. Manually delete: {yolov9_path.absolute()}\")\n",
    "            print(\"  2. Run this cell again\")\n",
    "            print(\"\\nOR set force_reclone=True in the function call below\")\n",
    "            raise FileNotFoundError(\"Incomplete YOLOv9 installation\")\n",
    "        \n",
    "        print(\"Cloning YOLOv9 repository...\")\n",
    "        try:\n",
    "            subprocess.run([\n",
    "                'git', 'clone', \n",
    "                'https://github.com/WongKinYiu/yolov9.git',\n",
    "                str(yolov9_path)\n",
    "            ], check=True, capture_output=True, text=True)\n",
    "            print(\"Repository cloned successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to clone repository: {e}\")\n",
    "            print(\"Make sure git is installed and accessible from command line\")\n",
    "            raise\n",
    "    \n",
    "    # Verify structure\n",
    "    required_files = [\n",
    "        'train.py',\n",
    "        'models/detect/yolov9-c.yaml',\n",
    "        'data/hyps/hyp.scratch-high.yaml'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nVerifying repository structure...\")\n",
    "    all_exist = True\n",
    "    for file in required_files:\n",
    "        file_path = yolov9_path / file\n",
    "        status = \"Found\" if file_path.exists() else \"Missing\"\n",
    "        print(f\"  {file}: {status}\")\n",
    "        if not file_path.exists():\n",
    "            all_exist = False\n",
    "    \n",
    "    if not all_exist:\n",
    "        print(\"\\nRepository structure incomplete.\")\n",
    "        print(\"Try running with force_reclone=True\")\n",
    "        raise FileNotFoundError(\"Repository structure incomplete\")\n",
    "    \n",
    "    return yolov9_path\n",
    "\n",
    "# Change force_reclone=True if you want to force a fresh clone\n",
    "yolov9_dir = setup_yolov9_repository(force_reclone=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_file = yolov9_dir / 'requirements.txt'\n",
    "if requirements_file.exists():\n",
    "    print(\"Installing YOLOv9 requirements...\")\n",
    "    subprocess.run([\n",
    "        sys.executable, '-m', 'pip', 'install', '-r', \n",
    "        str(requirements_file)\n",
    "    ], check=True)\n",
    "    print(\"Requirements installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Compatibility Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_torch_load(yolov9_dir):\n",
    "    '''\n",
    "    Update torch.load calls for PyTorch 2.6+ compatibility\n",
    "    '''\n",
    "    train_file = yolov9_dir / 'train.py'\n",
    "    \n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    if 'weights_only=False' in content:\n",
    "        print(\"torch.load already updated\")\n",
    "        return\n",
    "    \n",
    "    original = \"torch.load(weights, map_location='cpu')\"\n",
    "    patched = \"torch.load(weights, map_location='cpu', weights_only=False)\"\n",
    "    \n",
    "    if original in content:\n",
    "        content = content.replace(original, patched)\n",
    "        with open(train_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(\"Updated train.py for PyTorch 2.6+\")\n",
    "    else:\n",
    "        print(\"torch.load pattern not found\")\n",
    "\n",
    "def patch_loss_tal(yolov9_dir):\n",
    "    '''\n",
    "    Handle AuxLoss tuple structure in loss calculation\n",
    "    '''\n",
    "    loss_file = yolov9_dir / 'utils' / 'loss_tal.py'\n",
    "    \n",
    "    if not loss_file.exists():\n",
    "        print(\"loss_tal.py not found\")\n",
    "        return\n",
    "    \n",
    "    with open(loss_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    if '# Updated for AuxLoss compatibility' in content:\n",
    "        print(\"loss_tal.py already updated\")\n",
    "        return\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    patched = False\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if 'pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0]' in line:\n",
    "            if i > 0 and 'Updated' in lines[i-1]:\n",
    "                print(\"Already updated\")\n",
    "                return\n",
    "            \n",
    "            indent = len(line) - len(line.lstrip())\n",
    "            patch_lines = [\n",
    "                ' ' * indent + '# Updated for AuxLoss compatibility',\n",
    "                ' ' * indent + 'if isinstance(feats, (tuple, list)) and len(feats) > 0:',\n",
    "                ' ' * indent + '    if isinstance(feats[0], (tuple, list)):',\n",
    "                ' ' * indent + '        feats = feats[0]'\n",
    "            ]\n",
    "            lines = lines[:i] + patch_lines + lines[i:]\n",
    "            patched = True\n",
    "            break\n",
    "    \n",
    "    if patched:\n",
    "        with open(loss_file, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(lines))\n",
    "        print(\"Updated loss_tal.py for AuxLoss\")\n",
    "    else:\n",
    "        print(\"Pattern not found in loss_tal.py\")\n",
    "\n",
    "def patch_plots_pillow(yolov9_dir):\n",
    "    '''\n",
    "    Update deprecated Pillow getsize() method\n",
    "    '''\n",
    "    plots_file = yolov9_dir / 'utils' / 'plots.py'\n",
    "    \n",
    "    if not plots_file.exists():\n",
    "        print(\"plots.py not found\")\n",
    "        return\n",
    "    \n",
    "    with open(plots_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    if any('# Updated for Pillow' in line for line in lines):\n",
    "        print(\"plots.py already updated\")\n",
    "        return\n",
    "    \n",
    "    patched = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'self.font.getsize(label)' in line and 'w, h =' in line:\n",
    "            indent = len(line) - len(line.lstrip())\n",
    "            spaces = ' ' * indent\n",
    "            \n",
    "            lines[i] = f'{spaces}# Updated for Pillow 10+\\n'\n",
    "            lines.insert(i+1, f'{spaces}bbox = self.font.getbbox(label)\\n')\n",
    "            lines.insert(i+2, f'{spaces}w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]\\n')\n",
    "            patched = True\n",
    "            break\n",
    "    \n",
    "    if patched:\n",
    "        with open(plots_file, 'w', encoding='utf-8') as f:\n",
    "            f.writelines(lines)\n",
    "        print(\"Updated plots.py for Pillow 10+\")\n",
    "    else:\n",
    "        print(\"getsize() not found in plots.py\")\n",
    "\n",
    "print(\"Applying compatibility patches...\\n\")\n",
    "patch_torch_load(yolov9_dir)\n",
    "patch_loss_tal(yolov9_dir)\n",
    "patch_plots_pillow(yolov9_dir)\n",
    "print(\"\\nPatching complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pretrained Weights Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pretrained_weights(yolov9_dir, model_size='yolov9-c'):\n",
    "    '''\n",
    "    Download pretrained YOLOv9 weights\n",
    "    \n",
    "    Args:\n",
    "        model_size: 'yolov9-c' (compact), 'yolov9-m' (medium), or 'yolov9-e' (extended)\n",
    "    '''\n",
    "    weights_dir = yolov9_dir / 'weights'\n",
    "    weights_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    weights_urls = {\n",
    "        'yolov9-c': 'https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt',\n",
    "        'yolov9-e': 'https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt',\n",
    "        'yolov9-m': 'https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-m.pt',\n",
    "    }\n",
    "    \n",
    "    weights_file = weights_dir / f'{model_size}.pt'\n",
    "    \n",
    "    if weights_file.exists():\n",
    "        print(f\"Weights already exist: {weights_file}\")\n",
    "        return weights_file\n",
    "    \n",
    "    print(f\"Downloading {model_size} pretrained weights...\")\n",
    "    urllib.request.urlretrieve(weights_urls[model_size], weights_file)\n",
    "    print(f\"Downloaded to {weights_file}\")\n",
    "    \n",
    "    return weights_file\n",
    "\n",
    "model_size = 'yolov9-c'\n",
    "weights_file = download_pretrained_weights(yolov9_dir, model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Configuration\n",
    "\n",
    "### Transfer Learning Modes\n",
    "\n",
    "**Fine-tuning (Recommended)**\n",
    "- Starts with pretrained COCO weights\n",
    "- Retrains all layers\n",
    "- Best accuracy for parking dataset\n",
    "- Training time: 2-4 hours on GPU\n",
    "\n",
    "**Freeze Backbone**\n",
    "- Starts with pretrained COCO weights\n",
    "- Only trains detection head\n",
    "- Faster but less accurate\n",
    "- Training time: 1-2 hours on GPU\n",
    "\n",
    "**From Scratch**\n",
    "- No pretrained weights\n",
    "- Trains from random initialization\n",
    "- Usually worse results without large dataset\n",
    "- Training time: 3-5 hours on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_yaml': './prepared_data/yolo/data.yaml',\n",
    "    'model_size': 'yolov9-c',\n",
    "    'epochs': 100,\n",
    "    'batch_size': 4,\n",
    "    'img_size': 640,\n",
    "    'device': '0',\n",
    "    'workers': 0,\n",
    "    'project': 'runs/train',\n",
    "    'name': 'carpk_yolov9',\n",
    "    'transfer_learning_mode': 'finetune',\n",
    "    'patience': 10\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "data_yaml_path = Path(config['data_yaml'])\n",
    "if not data_yaml_path.exists():\n",
    "    raise FileNotFoundError(f\"Data YAML not found: {data_yaml_path}\")\n",
    "else:\n",
    "    print(f\"\\nData YAML verified: {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pre-training Diagnostics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check data.yaml\n",
    "data_yaml_path = Path(config['data_yaml'])\n",
    "print(f\"\\n1. Data YAML Check:\")\n",
    "print(f\"   Path: {data_yaml_path.absolute()}\")\n",
    "print(f\"   Exists: {data_yaml_path.exists()}\")\n",
    "\n",
    "if data_yaml_path.exists():\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        yaml_content = f.read()\n",
    "    print(f\"\\n   Content:\")\n",
    "    print(\"   \" + \"\\n   \".join(yaml_content.split('\\n')))\n",
    "else:\n",
    "    print(\"   ERROR: data.yaml not found!\")\n",
    "\n",
    "# Check if images exist\n",
    "print(f\"\\n2. Image Directory Check:\")\n",
    "prepared_data_dir = Path('./prepared_data/yolo')\n",
    "if prepared_data_dir.exists():\n",
    "    train_dir = prepared_data_dir / 'images' / 'train'\n",
    "    val_dir = prepared_data_dir / 'images' / 'val'\n",
    "    print(f\"   Train dir exists: {train_dir.exists()}\")\n",
    "    if train_dir.exists():\n",
    "        train_images = list(train_dir.glob('*.jpg'))\n",
    "        print(f\"   Train images: {len(train_images)}\")\n",
    "    print(f\"   Val dir exists: {val_dir.exists()}\")\n",
    "    if val_dir.exists():\n",
    "        val_images = list(val_dir.glob('*.jpg'))\n",
    "        print(f\"   Val images: {len(val_images)}\")\n",
    "else:\n",
    "    print(\"   ERROR: prepared_data directory not found!\")\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "print(f\"\\n3. PyTorch/CUDA Check:\")\n",
    "import torch\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "# Check weights file\n",
    "print(f\"\\n4. Weights File Check:\")\n",
    "print(f\"   Path: {weights_file.absolute()}\")\n",
    "print(f\"   Exists: {weights_file.exists()}\")\n",
    "if weights_file.exists():\n",
    "    size_mb = weights_file.stat().st_size / (1024*1024)\n",
    "    print(f\"   Size: {size_mb:.1f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verifying exact paths...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "data_location = Path(r'c:\\Users\\justi\\Documents\\parking_analyzer\\parking_analyzer\\yolo\\prepared_data\\yolo')\n",
    "\n",
    "# Check exact structure\n",
    "train_images = data_location / 'train' / 'images'\n",
    "train_labels = data_location / 'train' / 'labels'\n",
    "val_images = data_location / 'val' / 'images'\n",
    "val_labels = data_location / 'val' / 'labels'\n",
    "\n",
    "print(f\"Train images: {train_images}\")\n",
    "print(f\"  Exists: {train_images.exists()}\")\n",
    "print(f\"  Count: {len(list(train_images.glob('*.jpg'))) if train_images.exists() else 0}\")\n",
    "\n",
    "print(f\"\\nTrain labels: {train_labels}\")\n",
    "print(f\"  Exists: {train_labels.exists()}\")\n",
    "print(f\"  Count: {len(list(train_labels.glob('*.txt'))) if train_labels.exists() else 0}\")\n",
    "\n",
    "print(f\"\\nVal images: {val_images}\")\n",
    "print(f\"  Exists: {val_images.exists()}\")\n",
    "print(f\"  Count: {len(list(val_images.glob('*.jpg'))) if val_images.exists() else 0}\")\n",
    "\n",
    "print(f\"\\nVal labels: {val_labels}\")\n",
    "print(f\"  Exists: {val_labels.exists()}\")\n",
    "print(f\"  Count: {len(list(val_labels.glob('*.txt'))) if val_labels.exists() else 0}\")\n",
    "\n",
    "# Check a sample label file\n",
    "if train_labels.exists():\n",
    "    sample_labels = list(train_labels.glob('*.txt'))\n",
    "    if sample_labels:\n",
    "        print(f\"\\nSample label file: {sample_labels[0].name}\")\n",
    "        with open(sample_labels[0], 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(f\"  Lines: {len(lines)}\")\n",
    "            if lines:\n",
    "                print(f\"  First line: {lines[0].strip()}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"Running training with captured output...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "original_dir = os.getcwd()\n",
    "\n",
    "try:\n",
    "    os.chdir(yolov9_dir)\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        'train.py',\n",
    "        '--data', str(Path(r'c:\\Users\\justi\\Documents\\parking_analyzer\\parking_analyzer\\yolo\\prepared_data\\yolo\\data.yaml')),\n",
    "        '--cfg', 'models/detect/yolov9-c.yaml',\n",
    "        '--hyp', 'data/hyps/hyp.scratch-high.yaml',\n",
    "        '--epochs', '1',\n",
    "        '--batch-size', '2',\n",
    "        '--img-size', '640',\n",
    "        '--device', 'cpu',\n",
    "        '--workers', '0',\n",
    "        '--project', '../test_run',\n",
    "        '--name', 'test',\n",
    "        '--weights', str(weights_file.absolute())\n",
    "    ]\n",
    "    \n",
    "    print(\"Running command...\")\n",
    "    print(' '.join(cmd))\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Run with output capture but ignore encoding errors\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "        errors='replace'  # Replace encoding errors with ?\n",
    "    )\n",
    "    \n",
    "    # Print output in real-time\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "    \n",
    "    # Wait for completion\n",
    "    process.wait()\n",
    "    \n",
    "    # Print any errors\n",
    "    stderr_output = process.stderr.read()\n",
    "    if stderr_output:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STDERR OUTPUT:\")\n",
    "        print(\"=\"*70)\n",
    "        print(stderr_output)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    if process.returncode == 0:\n",
    "        print(\"SUCCESS!\")\n",
    "    else:\n",
    "        print(f\"FAILED with exit code: {process.returncode}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "finally:\n",
    "    os.chdir(original_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"Running training with captured output...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "original_dir = os.getcwd()\n",
    "\n",
    "try:\n",
    "    os.chdir(yolov9_dir)\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        'train.py',\n",
    "        '--data', str(Path(r'c:\\Users\\justi\\Documents\\parking_analyzer\\parking_analyzer\\yolo\\prepared_data\\yolo\\data.yaml')),\n",
    "        '--cfg', 'models/detect/yolov9-c.yaml',\n",
    "        '--hyp', 'data/hyps/hyp.scratch-high.yaml',\n",
    "        '--epochs', '1',\n",
    "        '--batch-size', '2',\n",
    "        '--img-size', '640',\n",
    "        '--device', 'cpu',\n",
    "        '--workers', '0',\n",
    "        '--project', '../test_run',\n",
    "        '--name', 'test',\n",
    "        '--weights', str(weights_file.absolute())\n",
    "    ]\n",
    "    \n",
    "    print(\"Running command...\")\n",
    "    print(' '.join(cmd))\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Run with output capture but ignore encoding errors\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "        errors='replace'  # Replace encoding errors with ?\n",
    "    )\n",
    "    \n",
    "    # Print output in real-time\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "    \n",
    "    # Wait for completion\n",
    "    process.wait()\n",
    "    \n",
    "    # Print any errors\n",
    "    stderr_output = process.stderr.read()\n",
    "    if stderr_output:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STDERR OUTPUT:\")\n",
    "        print(\"=\"*70)\n",
    "        print(stderr_output)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    if process.returncode == 0:\n",
    "        print(\"SUCCESS!\")\n",
    "    else:\n",
    "        print(f\"FAILED with exit code: {process.returncode}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "finally:\n",
    "    os.chdir(original_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_yolov9(yolov9_dir, config, weights_file):\n",
    "    '''\n",
    "    Execute YOLOv9 training\n",
    "    '''\n",
    "    print(\"Starting YOLOv9 Training\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    original_dir = Path(os.getcwd())\n",
    "    data_yaml_abs = Path(config['data_yaml']).absolute()\n",
    "    project_abs = original_dir / config['project']\n",
    "    \n",
    "    # Verify data.yaml exists\n",
    "    if not data_yaml_abs.exists():\n",
    "        print(f\"ERROR: data.yaml not found at: {data_yaml_abs}\")\n",
    "        print(\"\\nPlease run the dataset preparation notebook first!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Data YAML: {data_yaml_abs}\")\n",
    "    \n",
    "    # Get absolute path to weights BEFORE changing directory\n",
    "    if config['transfer_learning_mode'] == 'scratch':\n",
    "        print(\"Training from scratch without pretrained weights\")\n",
    "        weights_path = ''\n",
    "    else:\n",
    "        weights_path = weights_file.absolute()\n",
    "        print(f\"Weights: {weights_path}\")\n",
    "        if config['transfer_learning_mode'] == 'finetune':\n",
    "            print(\"Fine-tuning: Retraining all layers\")\n",
    "        elif config['transfer_learning_mode'] == 'freeze_backbone':\n",
    "            print(\"Freeze mode: Only training detection head\")\n",
    "    \n",
    "    # Change to yolov9 directory\n",
    "    os.chdir(yolov9_dir)\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        'train.py',\n",
    "        '--data', str(data_yaml_abs),\n",
    "        '--cfg', f'models/detect/{config[\"model_size\"]}.yaml',\n",
    "        '--hyp', 'data/hyps/hyp.scratch-high.yaml',\n",
    "        '--epochs', str(config['epochs']),\n",
    "        '--batch-size', str(config['batch_size']),\n",
    "        '--img-size', str(config['img_size']),\n",
    "        '--device', str(config['device']),\n",
    "        '--workers', str(config['workers']),\n",
    "        '--project', str(project_abs),\n",
    "        '--name', config['name'],\n",
    "        '--exist-ok'\n",
    "    ]\n",
    "    \n",
    "    if weights_path:\n",
    "        cmd.extend(['--weights', str(weights_path)])\n",
    "    \n",
    "    if config['transfer_learning_mode'] == 'freeze_backbone':\n",
    "        cmd.extend(['--freeze', '10'])\n",
    "    \n",
    "    print(f\"\\nCommand:\")\n",
    "    print(' '.join(cmd))\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run with output streaming\n",
    "        process = subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,  # Combine stderr with stdout\n",
    "            text=True,\n",
    "            errors='replace'\n",
    "        )\n",
    "        \n",
    "        # Print output in real-time\n",
    "        for line in process.stdout:\n",
    "            print(line, end='')\n",
    "        \n",
    "        process.wait()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        if process.returncode == 0:\n",
    "            print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "            print(\"=\"*70)\n",
    "            print(f\"\\nResults: {project_abs / config['name']}\")\n",
    "            print(f\"Best weights: {project_abs / config['name'] / 'weights' / 'best.pt'}\")\n",
    "        else:\n",
    "            print(f\"TRAINING FAILED - Exit code: {process.returncode}\")\n",
    "            print(\"=\"*70)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nException occurred: {e}\")\n",
    "        raise\n",
    "        \n",
    "    finally:\n",
    "        os.chdir(original_dir)\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "train_yolov9(yolov9_dir, config, weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_dir = Path(config['project']) / config['name']\n",
    "\n",
    "print(\"Training Results:\")\n",
    "print(f\"Output directory: {results_dir}\")\n",
    "print(f\"Best weights: {results_dir / 'weights' / 'best.pt'}\")\n",
    "print(f\"Last weights: {results_dir / 'weights' / 'last.pt'}\")\n",
    "\n",
    "results_png = results_dir / 'results.png'\n",
    "if results_png.exists():\n",
    "    print(\"\\nTraining curves:\")\n",
    "    display(Image(filename=str(results_png)))\n",
    "else:\n",
    "    print(\"\\nresults.png not found\")\n",
    "\n",
    "val_batch_files = list(results_dir.glob('val_batch*.jpg'))\n",
    "if val_batch_files:\n",
    "    print(f\"\\nValidation predictions (showing first image):\")\n",
    "    display(Image(filename=str(val_batch_files[0])))\n",
    "else:\n",
    "    print(\"\\nNo validation batch images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verifying and forcing patch...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "general_file = yolov9_dir / 'utils' / 'general.py'\n",
    "\n",
    "with open(general_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Find the exact line and check what's around it\n",
    "found_line = None\n",
    "for i, line in enumerate(lines):\n",
    "    if 'device = prediction.device' in line:\n",
    "        found_line = i\n",
    "        print(f\"Found 'device = prediction.device' at line {i+1}\")\n",
    "        print(f\"\\nContext (lines {max(0,i-3)} to {min(len(lines),i+4)}):\")\n",
    "        for j in range(max(0, i-3), min(len(lines), i+4)):\n",
    "            print(f\"{j+1:4d}: {lines[j]}\", end='')\n",
    "        break\n",
    "\n",
    "if found_line is not None:\n",
    "    # Check if patch is before this line\n",
    "    check_range = lines[max(0, found_line-10):found_line]\n",
    "    has_patch = any('Handle AuxLoss' in line for line in check_range)\n",
    "    \n",
    "    print(f\"\\n\\nPatch already present: {has_patch}\")\n",
    "    \n",
    "    if not has_patch:\n",
    "        print(\"\\nApplying patch now...\")\n",
    "        indent = len(lines[found_line]) - len(lines[found_line].lstrip())\n",
    "        spaces = ' ' * indent\n",
    "        \n",
    "        patch_lines = [\n",
    "            f'{spaces}# Updated: Handle AuxLoss tuple output\\n',\n",
    "            f'{spaces}if isinstance(prediction, (list, tuple)):\\n',\n",
    "            f'{spaces}    if len(prediction) > 0 and isinstance(prediction[0], (list, tuple)):\\n',\n",
    "            f'{spaces}        prediction = prediction[0]\\n',\n",
    "            '\\n'\n",
    "        ]\n",
    "        \n",
    "        new_lines = lines[:found_line] + patch_lines + lines[found_line:]\n",
    "        \n",
    "        with open(general_file, 'w', encoding='utf-8') as f:\n",
    "            f.writelines(new_lines)\n",
    "        \n",
    "        print(\"Patch applied successfully!\")\n",
    "    else:\n",
    "        print(\"\\nPatch exists but not working. Checking patch content...\")\n",
    "        for j in range(max(0, found_line-10), found_line):\n",
    "            print(f\"{j+1:4d}: {lines[j]}\", end='')\n",
    "else:\n",
    "    print(\"Could not find 'device = prediction.device' line!\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patching val.py to handle AuxLoss output...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "val_file = yolov9_dir / 'val.py'\n",
    "\n",
    "with open(val_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Find where non_max_suppression is called in val.py\n",
    "patched = False\n",
    "for i, line in enumerate(lines):\n",
    "    if 'preds = non_max_suppression(preds' in line and 'Updated for AuxLoss' not in ''.join(lines[max(0,i-5):i]):\n",
    "        indent = len(line) - len(line.lstrip())\n",
    "        spaces = ' ' * indent\n",
    "        \n",
    "        # Insert patch before the non_max_suppression call\n",
    "        patch_lines = [\n",
    "            f'{spaces}# Updated for AuxLoss output\\n',\n",
    "            f'{spaces}if isinstance(preds, (list, tuple)) and len(preds) > 0:\\n',\n",
    "            f'{spaces}    if isinstance(preds[0], (list, tuple)):\\n',\n",
    "            f'{spaces}        preds = preds[0]  # Extract main predictions\\n',\n",
    "            '\\n'\n",
    "        ]\n",
    "        \n",
    "        new_lines = lines[:i] + patch_lines + lines[i:]\n",
    "        \n",
    "        with open(val_file, 'w', encoding='utf-8') as f:\n",
    "            f.writelines(new_lines)\n",
    "        \n",
    "        print(f\"Patched val.py at line {i+1}\")\n",
    "        patched = True\n",
    "        break\n",
    "\n",
    "if patched:\n",
    "    print(\"Successfully patched val.py\")\n",
    "else:\n",
    "    print(\"Could not patch val.py (may already be patched or line not found)\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running inference on test set using val.py...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "original_dir = Path(os.getcwd())\n",
    "\n",
    "try:\n",
    "    os.chdir(yolov9_dir)\n",
    "    \n",
    "    # Get absolute paths\n",
    "    best_weights = (original_dir / config['project'] / config['name'] / 'weights' / 'best.pt').absolute()\n",
    "    data_yaml_path = (original_dir / config['data_yaml']).absolute()\n",
    "    \n",
    "    print(f\"Weights: {best_weights}\")\n",
    "    print(f\"Data YAML: {data_yaml_path}\\n\")\n",
    "    \n",
    "    if not best_weights.exists():\n",
    "        print(\"ERROR: Best weights not found!\")\n",
    "    else:\n",
    "        # Use val.py to run on test set - it's more compatible\n",
    "        val_cmd = [\n",
    "            sys.executable,\n",
    "            'val.py',\n",
    "            '--data', str(data_yaml_path),\n",
    "            '--weights', str(best_weights),\n",
    "            '--batch-size', '1',\n",
    "            '--img-size', str(config['img_size']),\n",
    "            '--task', 'test',  # Run on test split\n",
    "            '--save-txt',\n",
    "            '--save-conf',\n",
    "            '--project', str(original_dir / config['project'] / config['name']),\n",
    "            '--name', 'test_results',\n",
    "            '--exist-ok'\n",
    "        ]\n",
    "        \n",
    "        print(\"Running validation on test set...\")\n",
    "        print(' '.join(val_cmd))\n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "        \n",
    "        process = subprocess.Popen(\n",
    "            val_cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            text=True,\n",
    "            errors='replace'\n",
    "        )\n",
    "        \n",
    "        for line in process.stdout:\n",
    "            print(line, end='')\n",
    "        \n",
    "        process.wait()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        if process.returncode == 0:\n",
    "            print(\"Test evaluation completed successfully!\")\n",
    "        else:\n",
    "            print(f\"Test evaluation failed with exit code: {process.returncode}\")\n",
    "        print(\"=\"*70)\n",
    "            \n",
    "finally:\n",
    "    os.chdir(original_dir)\n",
    "\n",
    "# Display results\n",
    "results_dir = original_dir / config['project'] / config['name'] / 'test_results'\n",
    "if results_dir.exists():\n",
    "    print(f\"\\nTest results saved to: {results_dir}\")\n",
    "    \n",
    "    # Look for prediction images\n",
    "    pred_images = sorted(list(results_dir.glob('*.jpg')) + list(results_dir.glob('*.png')))\n",
    "    if pred_images:\n",
    "        print(f\"\\nShowing first 3 test results:\")\n",
    "        for img_file in pred_images[:3]:\n",
    "            print(f\"\\n{img_file.name}:\")\n",
    "            display(Image(filename=str(img_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training is complete. The best model weights are saved and ready for evaluation or deployment.\n",
    "\n",
    "### Next Steps\n",
    "1. Review training curves in results.png\n",
    "2. Check validation predictions\n",
    "3. Run evaluation script for detailed metrics\n",
    "4. Use best.pt for inference on new images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
